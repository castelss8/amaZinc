{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from z3 import *\n",
    "\n",
    "from itertools import combinations\n",
    "from utils import *\n",
    "import shutil\n",
    "import numpy as np\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clustering(D):\n",
    "    '''\n",
    "    This function pairs up two items a and b into a new cluster if a is the closest item reachable from b and viceversa (D is not necessarily simmetrical) and \n",
    "    computes a new distance matrix where each cluster is represented as a single item (the distance from/to each cluster is the mean of the distances from/to the 2 items\n",
    "    of the cluster).\n",
    "\n",
    "    input   - D: list of lists; The distance matrix\n",
    "    output  - D_new: list of lists; The distance matrix after the new clusters are made\n",
    "            - clusters: list of lists; The list of every cluster\n",
    "    '''\n",
    "    list_of_mins=[]\n",
    "    n=len(D)-1\n",
    "    Closest=[] #Closest[i] will be the closest item to the i-th item\n",
    "    for item in range(n): \n",
    "        tmp = copy.deepcopy(D[item])\n",
    "        tmp[item]=1000\n",
    "        Closest.append(np.argmin(tmp[:-1])) \n",
    "        list_of_mins.append(np.min(tmp[:-1]))\n",
    "    \n",
    "    #Check what items can be paired up:\n",
    "    clusters=[]\n",
    "    already_in_cluster=[]\n",
    "    for item in range(n):\n",
    "        if item==Closest[Closest[item]] and (item not in already_in_cluster):\n",
    "            clusters.append([item, Closest[item]])\n",
    "            already_in_cluster.append(item)\n",
    "            already_in_cluster.append(Closest[item])\n",
    "        elif item!=Closest[Closest[item]]:\n",
    "            clusters.append([item])\n",
    "    clusters.append([n])\n",
    "    \n",
    "    #Build the new distance matrix\n",
    "    D_new=[]\n",
    "    n_new=len(clusters)-1\n",
    "    for row in range(n_new): \n",
    "        D_new.append([]) \n",
    "        for column in range(n_new): \n",
    "            if row==column:\n",
    "                D_new[row].append(0)\n",
    "            else:\n",
    "                tmp_dist=[] #store the distances from the item 'row' to the item 'column'. If one of the two is a cluster then len(tmp_dist)=2, if both of them are clusters then len(tmp_dist)=4, else len(tmp_dist)=1\n",
    "                for i in clusters[row]:\n",
    "                    for j in clusters[column]:\n",
    "                        tmp_dist.append(D[i][j])\n",
    "                D_new[row].append(np.mean(tmp_dist)) #The mean of the distances from the item/cluster 'row' to the item/cluster 'column'\n",
    "        tmp_dist=[]\n",
    "        #add the distance to the deposit\n",
    "        for i in clusters[row]:\n",
    "            tmp_dist.append(D[i][n])\n",
    "        D_new[row].append(np.mean(tmp_dist))\n",
    "    D_new.append([])\n",
    "\n",
    "    #add the last row (the distances from the deposit)\n",
    "    for column in range(n_new):\n",
    "        tmp_dist=[]\n",
    "        for i in clusters[column]:\n",
    "            tmp_dist.append(D[n][i])\n",
    "        D_new[n_new].append(np.mean(tmp_dist))\n",
    "    D_new[n_new].append(0)\n",
    "\n",
    "    return D_new, clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_names=[]\n",
    "file_names_mzn=[]\n",
    "file_names_clustering_mzn=[]\n",
    "for i in range(9):\n",
    "    file_names.append('inst0'+str(i+1)+'.dat')\n",
    "    file_names_mzn.append('inst0'+str(i+1)+'.dzn')\n",
    "    file_names_clustering_mzn.append('inst0'+str(i+1)+'_clusters.dzn')\n",
    "for i in range(12):\n",
    "    file_names.append('inst'+str(i+10)+'.dat')\n",
    "    file_names_mzn.append('inst'+str(i+10)+'.dzn')\n",
    "    file_names_clustering_mzn.append('inst'+str(i+10)+'_clusters.dzn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No Clustering for file: inst01.dat; Builded inst01.dzn; n=6\n",
      "No Clustering for file: inst02.dat; Builded inst02.dzn; n=9\n",
      "No Clustering for file: inst03.dat; Builded inst03.dzn; n=7\n",
      "No Clustering for file: inst04.dat; Builded inst04.dzn; n=10\n",
      "No Clustering for file: inst05.dat; Builded inst05.dzn; n=3\n",
      "No Clustering for file: inst06.dat; Builded inst06.dzn; n=8\n",
      "No Clustering for file: inst07.dat; Builded inst07.dzn; n=17\n",
      "No Clustering for file: inst08.dat; Builded inst08.dzn; n=10\n",
      "No Clustering for file: inst09.dat; Builded inst09.dzn; n=13\n",
      "No Clustering for file: inst10.dat; Builded inst10.dzn; n=13\n",
      "Clustering for file: inst11.dat; Builded inst11.dzn and inst11_clusters.dzn; n=143; n_new=40\n",
      "Clustering for file: inst12.dat; Builded inst12.dzn and inst12_clusters.dzn; n=95; n_new=43\n",
      "Clustering for file: inst13.dat; Builded inst13.dzn and inst13_clusters.dzn; n=47; n_new=26\n",
      "Clustering for file: inst14.dat; Builded inst14.dzn and inst14_clusters.dzn; n=215; n_new=61\n",
      "Clustering for file: inst15.dat; Builded inst15.dzn and inst15_clusters.dzn; n=239; n_new=72\n",
      "Clustering for file: inst16.dat; Builded inst16.dzn and inst16_clusters.dzn; n=47; n_new=27\n",
      "Clustering for file: inst17.dat; Builded inst17.dzn and inst17_clusters.dzn; n=287; n_new=73\n",
      "Clustering for file: inst18.dat; Builded inst18.dzn and inst18_clusters.dzn; n=191; n_new=50\n",
      "Clustering for file: inst19.dat; Builded inst19.dzn and inst19_clusters.dzn; n=71; n_new=33\n",
      "Clustering for file: inst20.dat; Builded inst20.dzn and inst20_clusters.dzn; n=287; n_new=86\n",
      "Clustering for file: inst21.dat; Builded inst21.dzn and inst21_clusters.dzn; n=143; n_new=36\n"
     ]
    }
   ],
   "source": [
    "NO_CLUSTERING = 35\n",
    "''' \n",
    "For every file decide if the clustering is necessary and build the necessary .dzn files\n",
    "'''\n",
    "for fn in range(21):\n",
    "    file_name=file_names[fn]\n",
    "\n",
    "    file = open('./Instances/'+file_name, 'r')\n",
    "    splitted_file = file.read().split('\\n')\n",
    "\n",
    "    n = int(splitted_file[1])\n",
    "    m = int(splitted_file[0])\n",
    "    cpt = list(map(int, splitted_file[2].split(' ')))\n",
    "    tmp_sz=splitted_file[3].split(' ')\n",
    "    if '' in tmp_sz:\n",
    "        sz=list(map(int, [tmp_sz[i] for i in range(len(tmp_sz)) if tmp_sz[i]!='']))\n",
    "    else:\n",
    "        sz = list(map(int, splitted_file[3].split(' ')))\n",
    "    D = [list(map(int, line.strip().split(' '))) for line in splitted_file[4:(n+5)]]\n",
    "        \n",
    "    if n<60:\n",
    "        clustering_iterations = 2\n",
    "    elif n<100:\n",
    "        clustering_iterations = 3\n",
    "    elif n<130:\n",
    "        clustering_iterations = 4\n",
    "    else:\n",
    "        clustering_iterations = 5\n",
    "\n",
    "    #No clustering needed:\n",
    "    if n<NO_CLUSTERING:\n",
    "        \n",
    "        file_name_mzn = file_names_mzn[fn]\n",
    "\n",
    "        file_2 = open('./Preprocessed_Instances/'+file_name_mzn, 'w')\n",
    "        file_2.write('m = '+str(m)+';\\n')\n",
    "        file_2.write('n = '+str(n)+';\\n')\n",
    "\n",
    "        file_2.write('l = ['+str(cpt[0]))\n",
    "        for c in cpt[1:]:\n",
    "            file_2.write(', ' + str(c))\n",
    "        file_2.write('];\\n')\n",
    "\n",
    "        file_2.write('s = ['+str(sz[0]))\n",
    "        for s in sz[1:]:\n",
    "            file_2.write(', ' + str(s))\n",
    "        file_2.write('];\\n')\n",
    "\n",
    "        file_2.write('D = [')\n",
    "        for line in D:\n",
    "            file_2.write('| ' + str(line[0]))\n",
    "            for el in line[1:]:\n",
    "                file_2.write(', ' + str(el))\n",
    "            file_2.write('\\n')\n",
    "        file_2.write('|];\\n')\n",
    "\n",
    "        file.close()\n",
    "        file_2.close()\n",
    "        print('No Clustering for file: '+ file_name +'; Builded '+file_name_mzn+'; n='+str(n))\n",
    "        \n",
    "\n",
    "    #Clustering:\n",
    "    else:\n",
    "        m = int(splitted_file[0])\n",
    "        cpt = list(map(int, splitted_file[2].split(' ')))\n",
    "        tmp_sz=splitted_file[3].split(' ')\n",
    "        if '' in tmp_sz:\n",
    "            sz=list(map(int, [tmp_sz[i] for i in range(len(tmp_sz)) if tmp_sz[i]!='']))\n",
    "        else:\n",
    "            sz = list(map(int, splitted_file[3].split(' ')))\n",
    "        D = [list(map(int, line.strip().split(' '))) for line in splitted_file[4:(n+5)]]\n",
    "\n",
    "        #Build D_new (the distance matrix after the clustering)\n",
    "        D_new=D\n",
    "        clusters=[ [i] for i in range(n+1) ]\n",
    "        for i in range(clustering_iterations):\n",
    "            D_new, new_clusters=clustering(D_new)\n",
    "            old_clusters=clusters\n",
    "            clusters=[]\n",
    "            for clus in new_clusters:\n",
    "                clusters.append([])\n",
    "                for item in clus:\n",
    "                    for old_item in old_clusters[item]:\n",
    "                        clusters[-1].append(old_item)\n",
    "        \n",
    "        for row in range(len(D_new)):\n",
    "            for column in range(len(D_new)):\n",
    "                D_new[row][column]=int(D_new[row][column]) #Turining D_new from a matrix of float into a matrix of int rounding down\n",
    "\n",
    "\n",
    "        n_new  = len(clusters) - 1\n",
    "        sz_new=[]\n",
    "        \n",
    "        #Build sz_new (the list of the items' sizes after the clustering)\n",
    "        for item in range(n_new):\n",
    "            sz_new.append(sum([sz[i] for i in clusters[item]]))\n",
    "        \n",
    "\n",
    "        file_name_mzn = file_names_mzn[fn]\n",
    "        file_2 = open('./Preprocessed_Instances/'+file_name_mzn, 'w')\n",
    "        \n",
    "        #write the .dzn file\n",
    "        file_2.write('m = '+str(m)+';\\n')\n",
    "        file_2.write('n = '+str(n_new)+';\\n')\n",
    "\n",
    "        file_2.write('l = ['+str(cpt[0]))\n",
    "        for c in cpt[1:]:\n",
    "            file_2.write(', ' + str(c))\n",
    "        file_2.write('];\\n')\n",
    "\n",
    "        file_2.write('s = ['+str(sz_new[0]))\n",
    "        for s in sz_new[1:]:\n",
    "            file_2.write(', ' + str(s))\n",
    "        file_2.write('];\\n')\n",
    "\n",
    "        file_2.write('D = [')\n",
    "        for line in D_new:\n",
    "            file_2.write('| ' + str(line[0]))\n",
    "            for el in line[1:]:\n",
    "                file_2.write(', ' + str(el))\n",
    "            file_2.write('\\n')\n",
    "        file_2.write('|];\\n\\n')\n",
    "\n",
    "        #write the clustering.dzn file\n",
    "        file_name_cluster_mzn = file_names_clustering_mzn[fn]\n",
    "        file_3 = open('./Preprocessed_Instances/'+file_name_cluster_mzn, 'w')\n",
    "        real_clusters = [clus for clus in clusters if len(clus)>1]\n",
    "\n",
    "        file_3.write('n = '+str(n)+';\\n')\n",
    "        file_3.write('k= '+str(len(real_clusters))+';\\n')\n",
    "        file_3.write('c = ['+str(len(real_clusters[0])))\n",
    "        for c in real_clusters[1:]:\n",
    "            file_3.write(', ' + str(len(c)))\n",
    "        file_3.write('];\\n')\n",
    "\n",
    "\n",
    "        file_3.write('D = [')\n",
    "        for line in D_new:\n",
    "            file_3.write('| ' + str(line[0]))\n",
    "            for el in line[1:]:\n",
    "                file_3.write(', ' + str(el))\n",
    "            file_3.write('\\n')\n",
    "        file_3.write('|];\\n')\n",
    "\n",
    "        file_3.write('C = [')\n",
    "\n",
    "        max_len=max([len(i) for i in real_clusters])\n",
    "\n",
    "        for clus in real_clusters:\n",
    "            file_3.write('| ' + str(clus[0]))\n",
    "            for el_id in range(max_len-1):\n",
    "                if el_id<len(clus)-1:\n",
    "                    file_3.write(', ' + str(clus[el_id+1]))\n",
    "                else:\n",
    "                    file_3.write(', -1')\n",
    "            file_3.write('\\n')\n",
    "        file_3.write('|];\\n')\n",
    "\n",
    "        file_3.close()\n",
    "        file_2.close()\n",
    "        file.close()\n",
    "        print('Clustering for file: '+ file_name +'; Builded '+file_name_mzn+' and '+file_name_cluster_mzn+'; n='+str(n)+'; n_new='+str(n_new))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
